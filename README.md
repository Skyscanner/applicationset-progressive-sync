# argocd-progressive-rollout

`argocd-progressive-rollout` is a controller to allow a progressive rollout of ArgoCD Applications generated by an ApplicationSet.

## Motivation

[Argo ApplicationSet](https://github.com/argoproj-labs/applicationset) is being developed as the solution to replace the `app-of-apps` pattern.

While `ApplicationSet` is great to programmatically generate ArgoCD Applications, we will still need to solve _how_ to update the Applications.

If we enable the `auto-sync` policy, we will update all the generated Applications at once.

This might not be a problem if we have only one production cluster, but organizations with tens or hundreds of clusters need to avoid a global rollout. They need to release new versions of their application in a safer way.

The `argocd progressive rollout` controller allows operators and developers to decide _how_ they want to update their Applications.

## Example `spec`

```yaml
apiVersion: deployment.skyscanner.net/v1alpha1
kind: ProgressiveRollout
metadata:
  name: myprogressiverollout
  namespace: argocd
spec:
  # a reference to the target ApplicationSet
  sourceRef:
    apiVersion: argoproj.io/v1alpha1
    kind: ApplicationSet
    name: myappset
    # the rollout steps
  stages:
      # human friendly name
    - name: two clusters as canary in EMEA
      # how many targets to update in parallel
      # can be an integer or %.
      maxParallel: 2
      # how many targets to update from the selector result
      # can be an integer or %.
      maxTargets: 2
      # which targets to update
      targets:
        clusters:
          selector:
            matchLabels:
              area: emea
    - name: rollout to remaining clusters
      maxParallel: 25%
      maxTargets: 100%
      targets:
        clusters:
          selector: {}
```

## Status: `pre-alpha`

Expect a non-functional controller and breaking changes until Milestone 2 is completed.

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md)

## Configuration

The controller connects to an Argo CD server and requires configuration to do so:
```
ARGOCD_AUTH_TOKEN: <token of the Argo CD user>
ARGOCD_SERVER_ADDR: <address of the Argo CD server>
```

The above configuration is loaded taking into account the following priority order:

1. Environment Variables.


```
ARGOCD_AUTH_TOKEN=ey...
ARGOCD_SERVER_ADDR=argocd-server
```


2. Files in the Config Directory.
```
.
├── .prcconfig
│   ├── ARGOCD_AUTH_TOKEN # file content: "ey..."
│   ├── ARGOCD_SERVER_ADDR # file content: "argocd-server"
```

If neither is present, the controller will **fail** to start.

## Development

### Local development with Kubebuilder

To get the controller running against the configured Kubernetes cluster in ~/.kube/config, run:

```
make install
make run
```

Please remember the `ARGOCD_AUTH_TOKEN` and `ARGOCD_SERVER_ADDR` variables need to be present in order 
to run against a Kubernetes cluster with Argo CD. If the cluster was configured using the `hack/setup-dev.sh` script,
these variables are part of the `.env.local` file.


### Deploying to a Kubernetes cluster

To deploy the controller to a Kubernetes cluster, run:
```
make install
make docker-build
make deploy
```

In order to so, a `.env.cluster` file needs to exist in the `config/manager` folder, containing
both required variables, in accordance with the provided `.example` file. 

If using `kind` clusters, docker images need to be loaded manually using `kind load docker-image <image>:<version> --name <cluster-name>`
.

### Setting up dev environment

To facilitate local debugging and testing against real clusters, you may run:

```
bash hack/install-dev-deps.sh
bash hack/setup-dev.sh [argocd-version] [appset-version]
make install
make deploy
```

this will install all the dependencies (`pre-commit`, `kubebuilder`, `argocd`, `kind`) and it will install the correct version of ArgoCD Application API package for you. If you omit `argocd-version` and/or `appset-version` it will default to the latest stable/tested versions of ArgoCD and Appset controller.

After running the script, you will have 3 kind clusters created locally:
 - `kind-argocd-control-plane` - cluster hosting the argocd installation and the progressive rollout operator. This cluster is also registered with Argo so that we can simulate using the same process for deploying to control cluster as well
 - `kind-prc-cluster-1` and `kind-prc-cluster-2` - are the target clusters for deploying the apps to.

 This gives us a total of 3 clusters allowing us to play with multiple stages of deploying. It will also log you in argocd cli. You can find additional login details in `.env.local` file that will be generated for your convenience.
 #### Regenerating your access

 In case that your access to the local argocd has become broken, you can regenerate it by running

 ```
 bash hack/login-argocd-local.sh
 ```

 This will create a socat link in kind docker network allowing you to access argocd server UI through your localhost.
 The exact port will be outputted after the command has been run. Running this command will also update the values in `.env.local`.

 #### Registering additional clusters

 If you want to create additional clusters, you can do so by running
 ```
 bash hack/add-cluster <cluster-name> <recreate>
 ```
 This will spin up another kind cluster and register it against ArgoCD running in `kind-argocd-control-plane`

 #### Deploying a test appset

You can deploy a test appset to the default 3 clusters by running the following:

```
bash hack/deploy-test-appset.sh
```
Feel free to extend the cluster generation section of the appset spec if you want to deploy it clusters that you have manually created.

#### Update ArgoCD Application API package

Because of [https://github.com/argoproj/argo-cd/issues/4055](https://github.com/argoproj/argo-cd/issues/4055) we can't just run `go get github.com/argoproj/argo-cd`.

Use `hack/install-argocd-application.sh` to install the correct version of the Application API.
